from __future__ import annotations
from typing import TYPE_CHECKING, cast
import json
from os import path as os_path
import sys
import logging

from blueshift.calendar.trading_calendar import TradingCalendar
from blueshift.lib.common.constants import CCY, Currency
from blueshift.lib.common.platform import ensure_directory, get_exception
from blueshift.lib.common.enums import BlotterType, AlgoMode
from blueshift.lib.exceptions import (
        BlueshiftException, ExceptionHandling, DataWriteException,
        InitializationError, TerminationError)
from blueshift.interfaces.assets._assets import MarketData
from blueshift.lib.serialize.json import convert_nan, BlueshiftJSONEncoder
from blueshift.config import blueshift_saved_performance_path
from blueshift.interfaces.trading.blotter import (
        IBlotter, register_blotter, serialize_asset_symbol)
from blueshift.interfaces.assets.assets import IAssetFinder
from blueshift.interfaces.trading.broker import IBacktestBroker
from blueshift.interfaces.data.data_portal import DataPortal

from ..analytics.pertrade import (
        create_txns_frame, create_positions_frame, 
        create_round_trips_frame)
from ..analytics.stats import create_report
from ..trackers._perfs import PerformanceTracker
from ..analytics.plotting import (
        get_main_plot, get_tear_sheet, save_main_plot)

if TYPE_CHECKING:
    import pandas as pd
    from blueshift.core.utils.environment import TradingEnvironment
else:
    import blueshift.lib.common.lazy_pandas as pd

class BacktestBlotter(IBlotter):
    """
        Blotter tracks the orders generated by the algo and matches them
        from the order status received from the broker API. It also computes
        the positions that should arise out of those algo orders and matches
        against the positions from broker API. Cumulative sum of the realized
        and unrealized pnls from these positions are algo pnl. This helps us
        avoid computing algo performance solely based on account information,
        as the account can also be affected by other means (manual trades or
        capital withdrawals etc.).

        Args:
            ``name (str)``: Unique name of the run.
            
            ``asset_finder (object)``: Asset finder object for the run.
            
            ``data_portal (object)``: Data portal object for the run.

            ``broker (object)``: Broker object for the run.

            ``env (object)``: trading environment.

            ``logger (object)``: Logger object of the run.

            ``init_capital (float)``: Ignored.

            ``timestamp (Timestamp)``: Timestamp at creation.

            ``ccy (object)``: Blotter currency.
            
            ``output_dir (str)``: Path to output directory.
            
    """
    _FREQ = 60000000000
    
    def __init__(self, name:str, asset_finder:IAssetFinder, data_portal:DataPortal, broker:IBacktestBroker, 
                 env:TradingEnvironment, logger:logging.Logger|None=None, init_capital:float|None=None, 
                 timestamp:pd.Timestamp|None=None, ccy:Currency=CCY.LOCAL, output_dir=None): # type: ignore
        IBlotter.__init__(self, name)
        
        self.ROUND_TRIPS_FILE = "round_trips.json"
        self.OPEN_TRADES_FILE = "open_trades.json"
        
        self._mode = AlgoMode.BACKTEST
        self.blotter_type = BlotterType.EXCLUSIVE
        self._ccy = ccy
        self._timestamp = timestamp
        self._daily_positions ={}
        self._daily_positions_combined ={}
        
        if not output_dir:
            self._output_dir = blueshift_saved_performance_path(name)
        else:
            self._output_dir = output_dir
        
        self._asset_finder = asset_finder
        self._data_portal = data_portal
        self._broker = broker

        if not self._broker.library:
            msg = f'Broker must have a library defined.'
            raise InitializationError(msg)
        
        self._env = env
        if not self._env:
            msg = f'Failed to create blotter, no trading environment '
            msg += f'supplied, nor found.'
            raise InitializationError(msg)
        
        
        if logger:
            self.logger = logger
        else:
            self.logger = self._env.logger
        
        #self.trading_calendar = broker.calendar
        self.trading_calendar = cast(TradingCalendar, self._env.trading_calendar)
        tz=self.trading_calendar.tz
        self._perfs_tracker = PerformanceTracker(
                name, self._mode, tz=tz, output_dir=self._output_dir)
        self._last_updated = None
        self._last_saved = None

        if not self._env.alert_manager:
            msg = f'No alert manager defined for the trading environment.'
            raise InitializationError(msg)
        
        self._quick_mode = False
        if self._env.quick:
            self._quick_mode = True
                
        self.set_benchmark()
        self._record_vars = pd.DataFrame()
            
    def _prefix_fn(self, timestamp, suffix='.json', dt_format="%Y%m%d"):
        return timestamp.date().strftime(dt_format) + suffix
    
    @property
    def mode(self):
        return self._mode
    
    @property
    def ccy(self):
        return self._broker.ccy
    
    @property
    def asset_finder(self):
        return self._asset_finder
    
    @property
    def data_portal(self):
        return self._data_portal
    
    @property
    def broker(self):
        return self._broker
    
    @property
    def performance_tracker(self):
        return self._perfs_tracker
        
    @property
    def timestamp(self) -> pd.Timestamp|None:
        return self._timestamp
    
    @timestamp.setter
    def timestamp(self, timestamp:pd.Timestamp):
        self._timestamp = timestamp
        for name in self.blotters:
            self.blotters[name].timestamp = timestamp
        
    @property
    def account(self):
        return self._broker.get_account()
        
    @property
    def orders(self):
        return self._broker.orders
    
    def _orders_no_reconcile(self):
        return self._broker.orders
        
    @property
    def open_orders(self):
        return self._broker.open_orders
    
    def open_orders_by_asset(self, asset):
        return self._broker.open_orders_by_asset(asset)
        
    @property
    def portfolio(self):
        return self._broker.positions.copy()
        
    @property
    def current_positions(self):
        return self._broker.positions
    
    @property
    def round_trips(self):
        return self._broker.round_trips
        
    @property
    def performance(self):
        return self._perfs_tracker.current_performance.copy()
        
    @property
    def perfs_history(self):
        perfs = self._perfs_tracker.to_dataframe()
        perfs.index = pd.to_datetime(perfs.index.astype('int64'))
        perfs.index = perfs.index.tz_localize('UTC').\
                            tz_convert(self.trading_calendar.tz)
        return perfs
        
    @property
    def current_performance(self):
        # for backtest, this is same as performance, as there is no
        # reconciliation trigger for backtest blotter.
        return self._perfs_tracker.current_performance
        
    @property
    def risk_report(self):
        return self._perfs_tracker.create_eod_report(self._quick_mode)
        
    @property
    def pnls(self):
        return self._perfs_tracker.to_dataframe_performance()
        
    @property
    def transactions(self):
        return self._broker.transactions
    
    @property
    def positions(self):
        return self._daily_positions
    
    def reset(self, timestamp=None, account=None, initial_positions=None, **kwargs) -> None:
        """
            Reset the blotter. this resets the transaction tracker as well.

            Args:
                ``account_net (float)``: To set the account value to.
                ``initial_positions (dict)``: A dict of positions as starting point.

            Returns:
                None.
        """
        if not initial_positions:
            initial_positions = {}
            
        self.broker.reset(open_positions=initial_positions)
        self._perfs_tracker.reset(self.account)
    
    def set_record_vars(self, record_vars):
        """ set the recorded vars from context. """
        self._record_vars = record_vars
    
    def _save(self, timestamp=None, *args, **kwargs):
        if self._quick_mode:
            # save nothing in quick mode
            return
        
        if self._last_saved and self._last_saved == timestamp:
            return
        
        perfs = pd.DataFrame()
        try:
            perfs = self._perfs_tracker._save(timestamp)
        except Exception as e:
            if isinstance(e, TerminationError):
                raise
                
            if self.logger:
                exc_type, exc_value, exc_traceback = sys.exc_info()
                err_msg = get_exception(exc_type, exc_value, exc_traceback)
                self.logger.info(err_msg)
                
            msg = f"failed to save performance data in blotter:{str(e)}"
            handling = ExceptionHandling.WARN
            raise DataWriteException(msg=msg, handling=handling)
        
        txns_df = pd.DataFrame()
        try:
            txns_df = create_txns_frame(
                    self.transactions, tz=self.trading_calendar.tz)
            if not txns_df.empty:
                fname = 'transactions.csv'
                fname = os_path.join(self._output_dir, fname)
                txns_df.to_csv(fname)
        except Exception as e:
            if isinstance(e, TerminationError):
                raise
            if self.logger:
                exc_type, exc_value, exc_traceback = sys.exc_info()
                err_msg = get_exception(exc_type, exc_value, exc_traceback)
                self.logger.info(err_msg)
                
            msg = f"failed to process transaction data in blotter:{str(e)}"
            handling = ExceptionHandling.WARN
            raise DataWriteException(msg=msg, handling=handling)
            
        pos_df = pd.DataFrame()
        try:
            pos_df = create_positions_frame(self.positions)
            if not pos_df.empty:
                fname = 'positions.csv'
                fname = os_path.join(self._output_dir, fname)
                pos_df.to_csv(fname)
        except (TypeError, KeyError, BlueshiftException) as e:
            if self.logger:
                exc_type, exc_value, exc_traceback = sys.exc_info()
                err_msg = get_exception(exc_type, exc_value, exc_traceback)
                self.logger.info(err_msg)
                
            msg = f"failed to process positions data in blotter:{str(e)}"
            handling = ExceptionHandling.WARN
            raise DataWriteException(msg=msg, handling=handling)
            
        trip_df = pd.DataFrame()
        try:
            if self.round_trips:
                trip_df = create_round_trips_frame(
                        self.round_trips, perfs.net)
                if not trip_df.empty:
                    fname = 'round_trips.csv'
                    fname = os_path.join(self._output_dir, fname)
                    trip_df.to_csv(fname)
        except (TypeError, OSError) as e:
            if self.logger:
                exc_type, exc_value, exc_traceback = sys.exc_info()
                err_msg = get_exception(exc_type, exc_value, exc_traceback)
                self.logger.info(err_msg)
                
            msg = f"failed to process round trips data in blotter:{str(e)}"
            handling = ExceptionHandling.WARN
            raise DataWriteException(msg=msg, handling=handling)
        
        report, round_trips = {}, pd.DataFrame()
        try:
            if not perfs.empty:
                report, round_trips = create_report(
                        perfs, round_trips=trip_df)
            if not round_trips.empty:
                fname = 'pertrade.csv'
                round_trips.to_csv(os_path.join(self._output_dir, fname))
            if report:
                fname = 'stats.json'
                fname = os_path.join(self._output_dir, fname)
                with open(fname, 'w') as fp:
                    convert_nan(report)
                    json.dump(report, fp, cls=BlueshiftJSONEncoder)
        except (TypeError, OSError) as e:
            if self.logger:
                exc_type, exc_value, exc_traceback = sys.exc_info()
                err_msg = get_exception(exc_type, exc_value, exc_traceback)
                self.logger.info(err_msg)
                
            msg = f"failed to process stats and per trade data in blotter:{str(e)}"
            handling = ExceptionHandling.WARN
            raise DataWriteException(msg=msg, handling=handling)
            
        try:
            if not self._record_vars.empty:
                fname = 'record_vars.csv'
                self._record_vars.to_csv(
                        os_path.join(self._output_dir, fname))
        except (TypeError, OSError) as e:
            if self.logger:
                exc_type, exc_value, exc_traceback = sys.exc_info()
                err_msg = get_exception(exc_type, exc_value, exc_traceback)
                self.logger.info(err_msg)
                
            msg = f"failed to process recorded variables data in blotter:{str(e)}"
            handling = ExceptionHandling.WARN
            raise DataWriteException(msg=msg, handling=handling)
            
        try:
            if not perfs.empty and self.parent is None:
                # save chart only for top-level blotter, and save it
                # for the combined performance
                if self.blotters:
                    trackers = [self.blotters[k].performance_tracker for k in self.blotters]
                    perfs = self._perfs_tracker.create_performance(trackers)
                target = os_path.join(self._output_dir, 'chart.png')
                save_main_plot(perfs, target, theme=self._env.theme)
                
                return_div = False if self._env.platform == 'cli' else True
                main_plot = get_main_plot(perfs, return_div=return_div, theme=self._env.theme)
                fname = 'main.html'
                
                if main_plot:
                    with open(os_path.join(
                            self._output_dir, fname),'w') as fp:
                        fp.write(main_plot)
                
                trip_df = create_round_trips_frame(
                        self.get_round_trips(), perfs.net)
                _, round_trips = create_report(perfs, round_trips=trip_df)
                pos_df = create_positions_frame(self._daily_positions_combined)
                
                tear_plot = get_tear_sheet(
                        perfs, pos=pos_df, per_trade=round_trips, 
                        records=self._record_vars, return_div=return_div, theme=self._env.theme)
                fname = 'tear_sheet.html'
                
                if tear_plot:
                    with open(os_path.join(
                            self._output_dir, fname),'w') as fp:
                        fp.write(tear_plot)
                        
                if self.blotters:
                    # save combined performance if required.
                    fname = os_path.join(self._output_dir, 'combined.csv')
                    perfs.to_csv(fname)
        except (TypeError, OSError) as e:
            if self.logger:
                exc_type, exc_value, exc_traceback = sys.exc_info()
                err_msg = get_exception(exc_type, exc_value, exc_traceback)
                self.logger.info(err_msg)
                
            msg = f"failed to wite chart data in blotter:{str(e)}"
            handling = ExceptionHandling.WARN
            raise DataWriteException(msg=msg, handling=handling)
            
        self._last_saved = timestamp
    
    def _read(self, *args, **kwargs):
        """
            Read/ reload the blotter.
        """
        pass
    
    def _roll(self, timestamp):
        try:
            self._daily_positions[timestamp] = {}
            current_positions = self.portfolio
            for asset in current_positions:
                pos = current_positions[asset]
                sym = serialize_asset_symbol(asset)
                self._daily_positions[timestamp][sym]=pos.to_json()
                
            
            self._daily_positions_combined[timestamp] = {}
            current_positions = self.get_open_positions()
            for asset in current_positions:
                pos = current_positions[asset]
                sym = serialize_asset_symbol(asset)
                self._daily_positions_combined[timestamp][sym]=pos.to_json()
                
            self._perfs_tracker.update_metrics(
                    self._broker.get_account(), self.orders,
                    self.portfolio, timestamp.value)
            self._perfs_tracker.roll(timestamp)
            self._last_updated = timestamp
        except Exception as e:
            if isinstance(e, TerminationError):
                raise

            if self.logger:
                exc_type, exc_value, exc_traceback = sys.exc_info()
                err_msg = get_exception(exc_type, exc_value, exc_traceback)
                self.logger.info(err_msg)

            msg = f'failed to roll the blotter on {timestamp}, see logs for details: {str(e)}'
            raise BlueshiftException(msg=msg)
    
    def _finalize(self, timestamp, *args, **kwargs):
        exit_time = kwargs.pop('exit_time', False)
        if exit_time or self._last_updated is None or \
            self._last_updated and self._last_updated != timestamp:
            # update only if we are quitting before a roll
            try:
                self._perfs_tracker.update_metrics(
                        self._broker.get_account(), self.orders,
                        self.portfolio, timestamp.value)
                self._last_updated = timestamp
            except Exception as e:
                if isinstance(e, TerminationError):
                    raise

                if self.logger:
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    err_msg = get_exception(exc_type, exc_value, exc_traceback)
                    self.logger.info(err_msg)

                msg = f'failed to update performance tracker, see logs for details: {str(e)}'
                raise BlueshiftException(msg=msg)
        
        try:
            self.update_perf_report(timestamp)
        except Exception as e:
            if isinstance(e, TerminationError):
                raise
            msg = f'failed to create performance report: {str(e)}'
            raise BlueshiftException(msg=msg)
        
        self._save(timestamp)
        
    def set_benchmark(self, benchmark=None):
        """
            Set up benchmark handling. Benchmark can be either a symbol 
            available in the daily data portal, or a csv file location or a 
            pandas Series object. The benchmark related calculations are 
            triggered daily and input benchmark data (if not a symbol) is 
            assumed to have daily frequency.
        """
        if not self._broker.library:
            return
        
        if not benchmark:
            benchmark = self._env.benchmark
                
        if benchmark is None:
            try:
                benchmark = self._broker.library.get_benchmark(
                        self._env.start_dt, self._env.end_dt)
            except Exception:
                self._benchmark = None
                #self._benchmark_rets = None
                msg = 'No benchmark specified. Backtest will run without benchmark.'
                msg = msg + ' Some metrics related to benchmark will be missing.'
                self.logger.warning(msg)
                return
        elif isinstance(benchmark, str):
            if benchmark.endswith('.csv'):
                benchmark = pd.read_csv(benchmark, index_col=0)
                benchmark.index = pd.DatetimeIndex(
                        pd.to_datetime(benchmark.index))
                if benchmark.index.tz: # type: ignore
                    benchmark.index = benchmark.index.tz_convert( # type: ignore
                            self.trading_calendar.tz)
                else:
                    benchmark.index = benchmark.index.tz_localize( # type: ignore
                            self.trading_calendar.tz)
                benchmark.index = benchmark.index.normalize() # type: ignore
                benchmark = benchmark.iloc[:,0]
            else:
                start_dt = self._env.start_dt
                end_dt = self._env.end_dt
                start_dt = cast(pd.Timestamp, start_dt)
                end_dt = cast(pd.Timestamp, end_dt)
                asset = self._broker.library.symbol(benchmark)
                benchmark = self._broker.library.read_between(
                        asset,'close',start_dt, end_dt, frequency='1d')
        elif isinstance(benchmark, MarketData):
            start_dt = self._env.start_dt
            end_dt = self._env.end_dt
            start_dt = cast(pd.Timestamp, start_dt)
            end_dt = cast(pd.Timestamp, end_dt)
            asset = self._broker.library.symbol(benchmark.symbol)
            benchmark = self._broker.library.read_between(
                    asset,'close',start_dt, end_dt, frequency='1d')
            
        if not isinstance(benchmark, pd.Series):
            msg = f'benchmark must be a csv file location, a valid symbol'
            msg = msg + f' or a pandas series with date-time index.'
            raise InitializationError(msg)
        
        if benchmark.empty:
            msg = 'No data for benchmark. Backtest will run without benchmark.'
            msg = msg + ' Some metrics related to benchmark will be missing.'
            self.logger.warning(msg)
            return
        
        if isinstance(benchmark.index, pd.DatetimeIndex):
            if benchmark.index.tz:
                benchmark.index = benchmark.index.tz_convert(self._broker.tz)
            else:
                benchmark.index = benchmark.index.tz_localize(
                        'Etc/UTC').tz_convert(self._broker.tz)
        
        self._perfs_tracker.set_benchmark(benchmark)
        
    def update_benchmark(self, timestamp=None, benchmark=None):
        """
            For backtest, this method does not apply as we fetch the 
            whole benchmark data during the `set_benchmark` call.
        """
        pass
    
    def update_perf_report(self, timestamp):
        """
            Compute host of analytics. For backtest usually this will be
            called at the end of the algo run. For live mode, this is
            called at end-of-day. This includes a per-trade analytics pack,
            a transaction reports pack and a risk statistics pack.
        """
        pass
    
    def check_on_restart(self, *args, **kwargs):
        """
            Do validation, if any, on an algo restart.
        """
        pass
        
    def reconcile(self, *args, **kwargs):
        """
            Reconcile algo transactions, positions and accounts with 
            broker values.
        """
        return True
        
    def update_valuation(self, *args, **kwargs):
        """
            Update position valuations.
        """
        return True
    
    def add_transactions(self, *args, **kwargs):
        """
            Add a transactions for future reconciliation.
        """
        pass
    
    def simulate(self, timestamp):
        self.broker.backtest_simulate(timestamp)
        
        for name in self.blotters:
            self.blotters[name].simulate(timestamp=timestamp)
    
    def add_blotter(self, strategy, timestamp=None):
        """ 
            Add a botter.
        """
        broker = self._env.create_broker_copy(strategy.initial_capital)
        output_dir = os_path.join(
                blueshift_saved_performance_path(self.name), 
                strategy.name)
        ensure_directory(output_dir)
        
        blotter = BacktestBlotter(
                strategy.name, 
                self._asset_finder,
                self._data_portal,
                broker=broker, # type: ignore
                logger=self.logger, 
                init_capital=strategy.initial_capital, 
                timestamp=timestamp, 
                env=self._env, 
                ccy=self._ccy,
                output_dir=output_dir)
        
        self.blotters[blotter.name] = blotter
        blotter.parent = self
        blotter.topic = self.name # it is always a child
        
        return blotter
            

register_blotter('backtest', BacktestBlotter)